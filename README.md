ğŸ¥ Medical Chatbot with RAG (FAISS + Hugging Face)

This project is a Retrieval-Augmented Generation (RAG) based Medical Chatbot.
It allows users to ask questions related to medical PDFs, and the chatbot answers strictly based on the uploaded documents, using vector search and a Hugging Face LLM.

 ğŸš€ Features

 ğŸ“„ Load and process medical PDF documents
 âœ‚ï¸ Split documents into chunks
 ğŸ§  Generate embeddings using Sentence Transformers
 ğŸ“¦ Store and retrieve vectors using FAISS
 ğŸ¤– Generate answers using Hugging Face Inference API
 ğŸ” Context-aware answers (no hallucination)
 âŒ Says â€œI donâ€™t knowâ€ if the answer is not in the documents

 ğŸ›  Tech Stack
 Python 3.10+
 LangChain
 FAISS
 Hugging Face Inference API
 Sentence-Transformers
 Transformers
 Dotenv

 ğŸ“ Project Structure
medical-chatbot-main/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ .pdf                   Medical PDF files
â”‚
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ db_faiss/               FAISS index (auto-created)
â”‚
â”œâ”€â”€ create_memory_llm.py        Build FAISS vector database
â”œâ”€â”€ connect_memory_with_llm.py  Query chatbot
â”‚
â”œâ”€â”€ .env                        Hugging Face token
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

 ğŸ”‘ Environment Setup
 1ï¸âƒ£ Create .env file
HF_TOKEN=your_huggingface_api_token_here
> Make sure your token has Inference API access.

 ğŸ“¦ Install Compatible Dependencies (IMPORTANT)
Use exact versions to avoid errors:

bash
pip install --force-reinstall \
  huggingface-hub==0.22.2 \
  transformers==4.38.0 \
  sentence-transformers==2.6.1 \
  langchain==0.1.15 \
  langchain-community==0.0.28 \
  langchain-huggingface==0.0.7 \
  faiss-cpu \
  python-dotenv




 âš™ï¸ Step-by-Step Usage

 âœ… Step 1: Build Vector Database
Add your medical PDFs inside the data/ folder, then run:

bash
python create_memory_llm.py

âœ” This will:
 Load PDFs
 Split into chunks
 Generate embeddings
 Store them in FAISS (vectorstore/db_faiss)

 âœ… Step 2: Run the Chatbot
bash
python connect_memory_with_llm.py
Example:
Write Query Here: What are the symptoms of diabetes?
 ğŸ§  How It Works (RAG Pipeline)

1. User enters a query
2. FAISS retrieves top-K relevant chunks
3. Context + question are merged into a prompt
4. Hugging Face LLM generates the answer
5. Sources are displayed



 âš ï¸ Important Notes

 The chatbot does NOT use the internet
 Answers are strictly based on PDFs
 Prevents hallucinations by design
 Uses manual RAG to ensure compatibility with older LangChain versions

 ğŸ§ª Common Issues & Fixes
 âŒ ValidationError: temperature in model_kwargs
âœ” Fixed by passing temperature explicitly to HuggingFaceEndpoint

 âŒ InferenceClient has no attribute post
âœ” Fixed by using compatible huggingface-hub version

 âŒ sentence-transformers import error
âœ” Fixed by downgrading huggingface-hub < 1.0

 ğŸ“Œ Future Improvements
 Streamlit UI
 User authentication
 Multi-PDF upload
 Medical image diagnosis
 Doctor recommendation system

 ğŸ‘¨â€ğŸ’» Author
Karan Kumar Ghosh
Bitan Bannerjee
Souhardya Nandy
Deeptangshu Sen
Suvajit Biswas
B.Tech CSE-IOT
Medical AI & Generative AI Projects


